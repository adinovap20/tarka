"""
This file contains the Parser that generates an abstract syntax tree
for the tokens generated by lexical analyzer.
"""

from tarka.ast import *
from tarka.errors import *
from tarka.token import Token, TokenType


class Parser:
    """
    Parser class
    """

    def __init__(self, tokens: list[Token]) -> None:
        """
        Creates instance of Parser class

        :param self: Parser
        :param tokens: list of tokens from which AST needs to be generated
        :type tokens: list[Token]
        """
        self.tokens = tokens
        self.tokensLen = len(tokens)
        self.curPos = int(0)
        self.curToken = Token(TokenType.EX_UNKNOWN, "\0", -1, -1) if self.tokensLen == 0 else self.tokens[self.curPos]

    def Parse(self) -> Program:
        """
        Generates the abstract syntax tree for the provided tokens

        :param self: Parser
        :return: Program root of the abstract syntax tree
        :rtype: Program
        """
        program = Program(0, 0, [])
        while self.curPos < self.tokensLen:
            stmt = self.__parseStmt()
            program.stmts.append(stmt)
        return program

    def __expect(self, expected: TokenType, look: int = 0) -> None:
        """
        Matches expected token and `look`th token after current token

        :param self: Parser
        :param expected: Expected TokenType
        :type expected: TokenType
        :param look: `look`th token to analyze after the current token
        :type look: int
        """
        if self.curPos + look >= self.tokensLen:
            raise ParserErrorUnexpectedTokenFoundEOF(expected, look, self.curToken.line, self.curToken.col)
        if self.tokens[self.curPos + look].type != expected:
            raise ParserErrorUnexpectedToken(expected, self.tokens[self.curPos])

    def __expectAndConsume(self, expected: TokenType) -> None:
        """
        Matches expected token and the current token and moves cursor forward

        :param self: Parser
        :param expected: Expected token type
        :type expected: TokenType
        """
        self.__expect(expected)
        self.curPos += 1
        if self.curPos >= self.tokensLen:
            return
        self.curToken = self.tokens[self.curPos]

    def __parseStmt(self) -> Statement:
        """
        Parses the statement and returns Statement node

        :param self: Parser
        :return: Statement Node
        :rtype: Statement
        """
        if self.curToken.type == TokenType.KW_EXIT:
            stmt = self.__parseExitStmt()
            return stmt
        else:
            raise ParserErrorNoMatchingStmt(self.curToken)

    def __parseExitStmt(self) -> ExitStmt:
        """
        Parses the exit statement and returns the ExitStmt Node

        :param self: Parser
        :return: ExitStmt Node
        :rtype: ExitStmt
        """
        line = self.curToken.line
        col = self.curToken.col
        self.__expectAndConsume(TokenType.KW_EXIT)
        expr = self.__parseExpr()
        self.__expectAndConsume(TokenType.EX_NEWLINE)
        return ExitStmt(line, col, expr)

    def __parseExpr(self) -> Expression:
        """
        Parses the expression and returns the Expression Node

        :param self: Parser
        :return: Expr Node
        :rtype: Expression
        """
        if self.curToken.type == TokenType.LIT_INT:
            expr = self.__parseIntLitExpr()
            return expr
        else:
            raise ParserErrorNoMatchingExpr(self.curToken)

    def __parseIntLitExpr(self) -> IntLitExpr:
        """
        Parses the integer literal expression and returns the IntLitExpr Node

        :param self: Parser
        :return: IntLitExpr Node
        :rtype: IntLitExpr
        """
        self.__expect(TokenType.LIT_INT)
        val = int(self.curToken.lit)
        line = self.curToken.line
        col = self.curToken.col
        self.__expectAndConsume(TokenType.LIT_INT)
        return IntLitExpr(line, col, val)
